{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0dd51225-ce9c-4cd6-bca3-ec4178654934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "43dab652-7fa3-4884-980f-8bf9f8f64eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_create_matrices(  train_file: Path,\n",
    "                                    test_file: Path ) -> Tuple[sp.csr_matrix, sp.csr_matrix, Dict[int, int], Dict[int, int]]:\n",
    "\n",
    "    raw_data = []\n",
    "\n",
    "    def parse_file(filepath: Path, dataset_type: str) -> None:\n",
    "        if not filepath.exists():\n",
    "            raise FileNotFoundError(f\"File not found: {filepath}\")\n",
    "\n",
    "        with filepath.open(\"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 2:\n",
    "                    continue\n",
    "\n",
    "                u_id = int(parts[0])\n",
    "                items = [int(i) for i in parts[1:]]\n",
    "\n",
    "                for i_id in items:\n",
    "                    raw_data.append(\n",
    "                        {\n",
    "                            \"user\": u_id,\n",
    "                            \"item\": i_id,\n",
    "                            \"type\": dataset_type,  # \"train\" or \"test\"\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    parse_file(train_file, \"train\")\n",
    "    parse_file(test_file, \"test\")\n",
    "\n",
    "    df = pd.DataFrame(raw_data)\n",
    "    print(f\"Loaded {len(df):,} total interactions.\")\n",
    "\n",
    "    df[\"user_idx\"] = df[\"user\"].astype(\"category\").cat.codes\n",
    "    df[\"item_idx\"] = df[\"item\"].astype(\"category\").cat.codes\n",
    "\n",
    "    # Internal index -> original ID\n",
    "    user_map: Dict[int, int] = dict(zip(df[\"user_idx\"], df[\"user\"]))\n",
    "    item_map: Dict[int, int] = dict(zip(df[\"item_idx\"], df[\"item\"]))\n",
    "\n",
    "    n_users = len(user_map)\n",
    "    n_items = len(item_map)\n",
    "\n",
    "    print(f\"Matrix dimensions: {n_users:,} users x {n_items:,} items\")\n",
    "\n",
    "    def build_csr(dataset_type: str) -> sp.csr_matrix:\n",
    "        subset = df[df[\"type\"] == dataset_type]\n",
    "\n",
    "        rows = subset[\"user_idx\"].values\n",
    "        cols = subset[\"item_idx\"].values\n",
    "        data = np.ones(len(subset), dtype=np.float32)\n",
    "\n",
    "        return sp.csr_matrix((data, (rows, cols)), shape=(n_users, n_items))\n",
    "\n",
    "    train_matrix = build_csr(\"train\")\n",
    "    test_matrix = build_csr(\"test\")\n",
    "\n",
    "    print(f\"Train nnz: {train_matrix.nnz:,} | Test nnz: {test_matrix.nnz:,}\")\n",
    "\n",
    "    return train_matrix, test_matrix, user_map, item_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e6503b6a-af54-4011-a0a6-9eacbb92fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemKNNRecommender:\n",
    "    \"\"\"\n",
    "    Item-Based Collaborative Filtering.\n",
    "    Logic: \"Users who liked Item A also liked Item B.\"\n",
    "    \"\"\"\n",
    "    def __init__(self, n_neighbors=20):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.model = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=n_neighbors, n_jobs=-1)\n",
    "        self.train_matrix = None\n",
    "        self.item_vectors = None\n",
    "\n",
    "    def fit(self, train_matrix):\n",
    "        \"\"\"\n",
    "        Trains the KNN model.\n",
    "        We want to calculate distance between ITEMS (rows).\n",
    "        \"\"\"\n",
    "        print(f\"Training Item-KNN (k={self.n_neighbors})...\")\n",
    "        self.train_matrix = train_matrix\n",
    "        \n",
    "        self.item_vectors = train_matrix.T\n",
    "        \n",
    "        # Fit the model on the Item Vectors\n",
    "        self.model.fit(self.item_vectors)\n",
    "\n",
    "    def predict(self, user_idx, top_k=20):\n",
    "        \"\"\"\n",
    "        Predicts items based on the user's history.\n",
    "        \"\"\"\n",
    "        # 1. Get User's History\n",
    "        user_history_indices = self.train_matrix[user_idx].indices\n",
    "        \n",
    "        if len(user_history_indices) == 0:\n",
    "            return np.array([])\n",
    "\n",
    "        query_indices = user_history_indices\n",
    "\n",
    "        query_vectors = self.item_vectors[query_indices]\n",
    "        distances, neighbor_indices = self.model.kneighbors(query_vectors)\n",
    "\n",
    "        candidate_scores = {}\n",
    "        for i in range(len(query_indices)):\n",
    "            for j in range(self.n_neighbors):\n",
    "                neighbor_idx = neighbor_indices[i, j]\n",
    "                similarity = 1.0 - distances[i, j]\n",
    "                \n",
    "                candidate_scores[neighbor_idx] = candidate_scores.get(neighbor_idx, 0) + similarity\n",
    "\n",
    "        for seen_idx in user_history_indices:\n",
    "            if seen_idx in candidate_scores:\n",
    "                del candidate_scores[seen_idx]\n",
    "\n",
    "        sorted_candidates = sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_indices = [idx for idx, score in sorted_candidates[:top_k]]\n",
    "        \n",
    "        return np.array(top_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e651d81-dd99-4e23-b157-17352942c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(predicted_indices, true_indices, k=20):\n",
    "    if len(true_indices) == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    # Slice to Top K\n",
    "    top_k_preds = predicted_indices[:k]\n",
    "    \n",
    "    relevance = np.isin(top_k_preds, true_indices).astype(float)\n",
    "    \n",
    "    discounts = np.log2(np.arange(2, len(relevance) + 2))\n",
    "    dcg = np.sum(relevance / discounts)\n",
    "    \n",
    "    # Ideal DCG\n",
    "    ideal_relevance = np.ones(min(len(true_indices), k))\n",
    "    ideal_discounts = np.log2(np.arange(2, len(ideal_relevance) + 2))\n",
    "    idcg = np.sum(ideal_relevance / ideal_discounts)\n",
    "    \n",
    "    return dcg / idcg if idcg > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3229498-68c1-47da-b405-026b0d52e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_pipeline(train_matrix, test_matrix, user_map, item_map, top_k=20, n_neighbors=20):\n",
    "    \"\"\"\n",
    "    Orchestrates the training and evaluation of the Item-KNN model.\n",
    "    Returns: output_df, avg_ndcg_score\n",
    "    \"\"\"\n",
    "\n",
    "    model = ItemKNNRecommender(n_neighbors=n_neighbors)\n",
    "    model.fit(train_matrix)\n",
    "\n",
    "    ndcg_scores = []\n",
    "    output_rows = []\n",
    "\n",
    "    test_users = np.unique(test_matrix.nonzero()[0])\n",
    "    n_test_users = len(test_users)\n",
    "\n",
    "    print(f\"Evaluating {n_test_users:,} users\")\n",
    "\n",
    "    for i, user_idx in tqdm(enumerate(test_users, 1), total=n_test_users, desc=\"Predicting\"):\n",
    "        \n",
    "        top_indices = model.predict(user_idx, top_k=top_k)\n",
    "        \n",
    "        true_items = test_matrix[user_idx].indices\n",
    "        score = ndcg_at_k(top_indices, true_items, k=top_k)\n",
    "        ndcg_scores.append(score)\n",
    "        \n",
    "        real_user_id = user_map.get(user_idx, f\"User_{user_idx}\")\n",
    "        real_item_ids = [item_map.get(idx, f\"Item_{idx}\") for idx in top_indices]\n",
    "        \n",
    "        output_rows.append({\n",
    "            'user_id': real_user_id,\n",
    "            'recommended_items': real_item_ids\n",
    "        })\n",
    "        \n",
    "        if i % 5000 == 0:\n",
    "            current_avg = np.mean(ndcg_scores)\n",
    "            tqdm.write(f\"Processed {i} users. Current Avg NDCG: {current_avg:.4f}\")\n",
    "\n",
    "    avg_ndcg = np.mean(ndcg_scores)\n",
    "    \n",
    "    print(f\"RESULTS:\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Evaluated Users: {len(ndcg_scores):,}\")\n",
    "    print(f\"Average NDCG@{top_k}: {avg_ndcg:.4f}\")\n",
    "    \n",
    "    return pd.DataFrame(output_rows), avg_ndcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e46a334-bcc6-45cf-8335-0cf640640f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2,372,615 total interactions.\n",
      "Matrix dimensions: 52,642 users x 88,416 items\n",
      "Train nnz: 1,918,235 | Test nnz: 454,380\n"
     ]
    }
   ],
   "source": [
    "K_VAL = 5\n",
    "\n",
    "INPUT_DIR = Path('Test_Train_Data')\n",
    "\n",
    "TRAIN_PATH = INPUT_DIR / f\"data_k{K_VAL}_train.txt\"\n",
    "TEST_PATH = INPUT_DIR / f\"data_k{K_VAL}_test.txt\"\n",
    "\n",
    "train_matrix, test_matrix, user_map, item_map = load_data_and_create_matrices(TRAIN_PATH, TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21721d9b-6e21-4d0e-ab39-f248578007ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Item-KNN (k=20)...\n",
      "Evaluating 52,642 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   9%|█████▉                                                         | 5000/52642 [12:03<1:34:56,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5000 users. Current Avg NDCG: 0.0830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  19%|███████████▊                                                  | 10001/52642 [22:31<1:24:55,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10000 users. Current Avg NDCG: 0.0822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|█████████████████▋                                            | 15002/52642 [32:29<1:01:38, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 15000 users. Current Avg NDCG: 0.0830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|████████████████████████▎                                       | 20000/52642 [42:32<51:49, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20000 users. Current Avg NDCG: 0.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  47%|█████████████████████████████▍                                | 25001/52642 [52:01<1:07:31,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 25000 users. Current Avg NDCG: 0.0935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  57%|███████████████████████████████████▎                          | 30002/52642 [1:01:37<38:05,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 30000 users. Current Avg NDCG: 0.1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|█████████████████████████████████████████▏                    | 35001/52642 [1:10:45<35:55,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 35000 users. Current Avg NDCG: 0.1078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████████████████████████████████████████████               | 40001/52642 [1:19:41<20:47, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 40000 users. Current Avg NDCG: 0.1146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  85%|█████████████████████████████████████████████████████         | 45002/52642 [1:28:28<13:27,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 45000 users. Current Avg NDCG: 0.1206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  95%|██████████████████████████████████████████████████████████▉   | 50001/52642 [1:37:05<04:33,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50000 users. Current Avg NDCG: 0.1263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████████████████████████████████████████████████████████| 52642/52642 [1:41:24<00:00,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:\n",
      "========================================\n",
      "Evaluated Users: 52,642\n",
      "Average NDCG@20: 0.1292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_df, final_score = knn_pipeline(train_matrix, test_matrix, user_map, item_map, top_k=20, n_neighbors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2f35c0a4-2581-4d4a-9131-7e68a6a14c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_recommendations(df: pd.DataFrame, filename_base: str = \"recommendations\", output_dir: str = \".\"):\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    csv_path = os.path.join(output_dir, f\"{filename_base}.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    txt_path = os.path.join(output_dir, f\"{filename_base}.txt\")\n",
    "    \n",
    "    with open(txt_path, 'w') as f:\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Writing TXT\"):\n",
    "            user_id = row['user_id']\n",
    "            items_str = \" \".join(map(str, row['recommended_items']))\n",
    "            f.write(f\"{user_id} {items_str}\\n\")\n",
    "            \n",
    "    print(f\"Saved results as TXT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "edebba5b-5f91-4627-923b-c2e4828bf1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing TXT: 100%|█████████████████████████████████████████████████████████████| 52642/52642 [00:07<00:00, 7439.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results as TXT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "save_recommendations(output_df, filename_base=\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8e5fa3-9568-46ee-9e2c-1aad52f46994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
