{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c51de5bb-d1e7-4396-8d21-10e680dc1ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d17915f8-1609-4ee8-93e7-5e0b91e82f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = Path('Processed_Data') \n",
    "\n",
    "OUTPUT_DIR = Path('Test_Train_Data')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ce02b3b-e5ef-46a2-b316-b6c4ae180dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RATIO = 0.2\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91ae4830-522c-4a42-9b54-3b985c60d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_split(file_path, test_ratio=0.2, seed=42):\n",
    "    \"\"\"\n",
    "    Reads a 'User Item1 Item2...' file.\n",
    "    Splits every user's items into Train/Test sets.\n",
    "    Returns two dictionaries: train_data, test_data.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    \n",
    "    train_lines = []\n",
    "    test_lines = []\n",
    "    \n",
    "    stats = {\n",
    "        'users': 0,\n",
    "        'train_interactions': 0,\n",
    "        'test_interactions': 0\n",
    "    }\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 2: continue\n",
    "            \n",
    "            user_id = parts[0]\n",
    "            items = parts[1:]\n",
    "            \n",
    "            random.shuffle(items)\n",
    "            \n",
    "            # 2. Determine Split Point\n",
    "            n_total = len(items)\n",
    "            n_test = int(n_total * test_ratio)\n",
    "\n",
    "            if n_test < 1 and n_total > 1:\n",
    "                n_test = 1\n",
    "\n",
    "            test_items = items[:n_test]\n",
    "            train_items = items[n_test:]\n",
    "\n",
    "            if train_items:\n",
    "                train_lines.append(f\"{user_id} {' '.join(train_items)}\\n\")\n",
    "                stats['train_interactions'] += len(train_items)\n",
    "                \n",
    "            if test_items:\n",
    "                test_lines.append(f\"{user_id} {' '.join(test_items)}\\n\")\n",
    "                stats['test_interactions'] += len(test_items)\n",
    "                \n",
    "            stats['users'] += 1\n",
    "            \n",
    "    return train_lines, test_lines, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6888d66-a966-4d3f-8bfe-159174a5ceb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data_k2.txt...\n",
      "   Users: 52,643\n",
      "   Train Interactions: 1,924,114\n",
      "   Test Interactions:  455,835 (19.15%)\n",
      "Processing data_k3.txt...\n",
      "   Users: 52,643\n",
      "   Train Interactions: 1,922,908\n",
      "   Test Interactions:  455,545 (19.15%)\n",
      "Processing data_k5.txt...\n",
      "   Users: 52,642\n",
      "   Train Interactions: 1,918,235\n",
      "   Test Interactions:  454,380 (19.15%)\n"
     ]
    }
   ],
   "source": [
    "input_files = sorted(list(INPUT_DIR.glob(\"data_k*.txt\")))\n",
    "\n",
    "for file_path in input_files:\n",
    "    filename = file_path.name\n",
    "    print(f\"Processing {filename}...\")\n",
    "\n",
    "    train_data, test_data, stats = process_and_split(file_path, TEST_RATIO, SEED)\n",
    "\n",
    "    base_name = file_path.stem # \"train_k5\"\n",
    "    train_out = OUTPUT_DIR / f\"{base_name}_train.txt\"\n",
    "    test_out = OUTPUT_DIR / f\"{base_name}_test.txt\"\n",
    "\n",
    "    with open(train_out, 'w') as f:\n",
    "        f.writelines(train_data)\n",
    "        \n",
    "    with open(test_out, 'w') as f:\n",
    "        f.writelines(test_data)\n",
    "\n",
    "    total_interactions = stats['train_interactions'] + stats['test_interactions']\n",
    "    test_pct = (stats['test_interactions'] / total_interactions) * 100\n",
    "    \n",
    "    print(f\"   Users: {stats['users']:,}\")\n",
    "    print(f\"   Train Interactions: {stats['train_interactions']:,}\")\n",
    "    print(f\"   Test Interactions:  {stats['test_interactions']:,} ({test_pct:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5719e80f-d917-491d-b84e-141db0e1a7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
