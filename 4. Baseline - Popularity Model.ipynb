{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c52f7766-9d96-4e80-874e-68028e068588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b5628a5f-2d19-4470-a1da-cc5f4a299693",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = Path('Test_Train_Data')\n",
    "\n",
    "TRAIN_PATH = INPUT_DIR / f\"data_k{K_VAL}_train.txt\"\n",
    "TEST_PATH = INPUT_DIR / f\"data_k{K_VAL}_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "86897d4d-20ac-49e4-8149-81e1f47f70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_create_matrices(  train_file: Path,\n",
    "                                    test_file: Path ) -> Tuple[sp.csr_matrix, sp.csr_matrix, Dict[int, int], Dict[int, int]]:\n",
    "\n",
    "    raw_data = []\n",
    "\n",
    "    def parse_file(filepath: Path, dataset_type: str) -> None:\n",
    "        if not filepath.exists():\n",
    "            raise FileNotFoundError(f\"File not found: {filepath}\")\n",
    "\n",
    "        with filepath.open(\"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 2:\n",
    "                    continue\n",
    "\n",
    "                u_id = int(parts[0])\n",
    "                items = [int(i) for i in parts[1:]]\n",
    "\n",
    "                for i_id in items:\n",
    "                    raw_data.append(\n",
    "                        {\n",
    "                            \"user\": u_id,\n",
    "                            \"item\": i_id,\n",
    "                            \"type\": dataset_type,  # \"train\" or \"test\"\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    parse_file(train_file, \"train\")\n",
    "    parse_file(test_file, \"test\")\n",
    "\n",
    "    df = pd.DataFrame(raw_data)\n",
    "    print(f\"Loaded {len(df):,} total interactions.\")\n",
    "\n",
    "    df[\"user_idx\"] = df[\"user\"].astype(\"category\").cat.codes\n",
    "    df[\"item_idx\"] = df[\"item\"].astype(\"category\").cat.codes\n",
    "\n",
    "    # Internal index -> original ID\n",
    "    user_map: Dict[int, int] = dict(zip(df[\"user_idx\"], df[\"user\"]))\n",
    "    item_map: Dict[int, int] = dict(zip(df[\"item_idx\"], df[\"item\"]))\n",
    "\n",
    "    n_users = len(user_map)\n",
    "    n_items = len(item_map)\n",
    "\n",
    "    print(f\"Matrix dimensions: {n_users:,} users x {n_items:,} items\")\n",
    "\n",
    "    def build_csr(dataset_type: str) -> sp.csr_matrix:\n",
    "        subset = df[df[\"type\"] == dataset_type]\n",
    "\n",
    "        rows = subset[\"user_idx\"].values\n",
    "        cols = subset[\"item_idx\"].values\n",
    "        data = np.ones(len(subset), dtype=np.float32)\n",
    "\n",
    "        return sp.csr_matrix((data, (rows, cols)), shape=(n_users, n_items))\n",
    "\n",
    "    train_matrix = build_csr(\"train\")\n",
    "    test_matrix = build_csr(\"test\")\n",
    "\n",
    "    print(f\"Train nnz: {train_matrix.nnz:,} | Test nnz: {test_matrix.nnz:,}\")\n",
    "\n",
    "    return train_matrix, test_matrix, user_map, item_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "89174184-0740-43ce-9825-badccbc49c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_popularity_model(train_matrix, test_matrix, user_map, item_map, top_k=20):\n",
    "    \"\"\"\n",
    "    Trains a Popularity Baseline model and evaluates it using NDCG@K.\n",
    "    \"\"\"\n",
    "    print(\"Calculating item popularity\")\n",
    "\n",
    "    global_item_scores = np.array(train_matrix.sum(axis=0)).flatten()\n",
    "\n",
    "    top_idx = global_item_scores.argmax()\n",
    "\n",
    "    # 2. Evaluation Loop\n",
    "    ndcg_scores = []\n",
    "    output_rows = []\n",
    "\n",
    "    test_users = np.unique(test_matrix.nonzero()[0])\n",
    "\n",
    "    print(f\"Processing {len(test_users):,} users with test data\")\n",
    "\n",
    "    for user_idx in test_users:\n",
    "        \n",
    "        user_scores = global_item_scores.copy()\n",
    "\n",
    "        known_indices = train_matrix[user_idx].indices\n",
    "        user_scores[known_indices] = -np.inf\n",
    "        \n",
    "        top_indices = user_scores.argsort()[-top_k:][::-1]\n",
    "        \n",
    "        true_items = test_matrix[user_idx].indices\n",
    "        \n",
    "        relevance = np.asfarray([1 if x in true_items else 0 for x in top_indices])\n",
    "        \n",
    "        if len(relevance) > 0:\n",
    "            dcg = np.sum(relevance / np.log2(np.arange(2, relevance.size + 2)))\n",
    "            ideal_rel = np.ones(min(len(true_items), top_k))\n",
    "            idcg = np.sum(ideal_rel / np.log2(np.arange(2, ideal_rel.size + 2)))\n",
    "            score = (dcg / idcg) if idcg > 0 else 0\n",
    "        else:\n",
    "            score = 0\n",
    "            \n",
    "        ndcg_scores.append(score)\n",
    "\n",
    "        real_user_id = user_map[user_idx]\n",
    "        real_item_ids = [item_map[i] for i in top_indices]\n",
    "        \n",
    "        output_rows.append({\n",
    "            'user_id': real_user_id,\n",
    "            'recommended_items': real_item_ids\n",
    "        })\n",
    "\n",
    "    avg_ndcg = np.mean(ndcg_scores)\n",
    "    print(f\"RESULT:\")\n",
    "    print(f\"Average NDCG@{top_k}: {avg_ndcg:.4f}\")\n",
    "    \n",
    "    return pd.DataFrame(output_rows), avg_ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1711ab24-ad3b-40f0-bfe3-245268e23ce3",
   "metadata": {},
   "source": [
    "## Min Interactions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "83b8102c-374f-43ea-b3c8-7773a4e22f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2,379,949 total interactions.\n",
      "Matrix dimensions: 52,643 users x 90,818 items\n",
      "Train nnz: 1,924,114 | Test nnz: 455,835\n"
     ]
    }
   ],
   "source": [
    "K_VAL = 2\n",
    "\n",
    "INPUT_DIR = Path('Test_Train_Data')\n",
    "\n",
    "TRAIN_PATH = INPUT_DIR / f\"data_k{K_VAL}_train.txt\"\n",
    "TEST_PATH = INPUT_DIR / f\"data_k{K_VAL}_test.txt\"\n",
    "\n",
    "train_matrix, test_matrix, user_map, item_map = load_data_and_create_matrices(TRAIN_PATH, TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "07fc82d0-d3f4-41c9-92b8-a03969119617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating item popularity\n",
      "Processing 52,643 users with test data\n",
      "RESULT:\n",
      "Average NDCG@20: 0.0079\n"
     ]
    }
   ],
   "source": [
    "output_df, score = evaluate_popularity_model(train_matrix, test_matrix, user_map, item_map, top_k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf14706-ab40-449d-9cef-766cf2d65843",
   "metadata": {},
   "source": [
    "## Min interaction 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "24b32e44-25d9-48b1-b7d6-d1749288d59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2,378,453 total interactions.\n",
      "Matrix dimensions: 52,643 users x 90,070 items\n",
      "Train nnz: 1,922,908 | Test nnz: 455,545\n"
     ]
    }
   ],
   "source": [
    "K_VAL = 3\n",
    "\n",
    "INPUT_DIR = Path('Test_Train_Data')\n",
    "\n",
    "TRAIN_PATH = INPUT_DIR / f\"data_k{K_VAL}_train.txt\"\n",
    "TEST_PATH = INPUT_DIR / f\"data_k{K_VAL}_test.txt\"\n",
    "\n",
    "\n",
    "train_matrix, test_matrix, user_map, item_map = load_data_and_create_matrices(TRAIN_PATH, TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b4b99e34-0367-4ebd-a940-089aa94a94ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating item popularity\n",
      "Processing 52,643 users with test data\n",
      "RESULT:\n",
      "Average NDCG@20: 0.0080\n"
     ]
    }
   ],
   "source": [
    "output_df, score = evaluate_popularity_model(train_matrix, test_matrix, user_map, item_map, top_k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63debaf-15c2-4d45-b6a6-460759bc2aef",
   "metadata": {},
   "source": [
    "## Min interaction 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "98510adc-23ad-4565-a82b-0eb0b3b81b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2,372,615 total interactions.\n",
      "Matrix dimensions: 52,642 users x 88,416 items\n",
      "Train nnz: 1,918,235 | Test nnz: 454,380\n"
     ]
    }
   ],
   "source": [
    "K_VAL = 5\n",
    "\n",
    "INPUT_DIR = Path('Test_Train_Data')\n",
    "\n",
    "TRAIN_PATH = INPUT_DIR / f\"data_k{K_VAL}_train.txt\"\n",
    "TEST_PATH = INPUT_DIR / f\"data_k{K_VAL}_test.txt\"\n",
    "\n",
    "\n",
    "train_matrix, test_matrix, user_map, item_map = load_data_and_create_matrices(TRAIN_PATH, TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5dc0f400-d3a2-4e37-9460-42ca894f1e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating item popularity\n",
      "Processing 52,642 users with test data\n",
      "RESULT:\n",
      "Average NDCG@20: 0.0081\n"
     ]
    }
   ],
   "source": [
    "output_df, score = evaluate_popularity_model(train_matrix, test_matrix, user_map, item_map, top_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a55187-5c09-440c-8457-7c295cdf626e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
